# Summary of Data Repositories and Big Data Technologies

## Data Repositories

A **Data Repository** is a general term for data that has been collected, organized, and isolated for reporting, analytics, and archival purposes. The main types of data repositories include:

- **Databases**: These can be relational or non-relational, each with its own organizational principles, data types, and querying tools.
  
- **Data Warehouses**: These consolidate incoming data into one comprehensive storehouse.
  
- **Data Marts**: Sub-sections of data warehouses, designed to isolate data for specific business functions or use cases.
  
- **Data Lakes**: Storage repositories for large amounts of structured, semi-structured, and unstructured data in their native format.
  
- **Big Data Stores**: Provide distributed computational and storage infrastructure to handle very large datasets.

## ETL Process

**ETL** (Extract, Transform, Load) is an automated process that converts raw data into analysis-ready data by:

1. **Extracting** data from source locations.
2. **Transforming** raw data through cleaning, enriching, standardizing, and validating it.
3. **Loading** the processed data into a destination system or data repository.

## Data Pipeline

A **Data Pipeline** encompasses the entire journey of moving data from the source to a destination (such as a data lake or application), utilizing the ETL process. It is sometimes used interchangeably with ETL.

## Big Data

**Big Data** refers to the vast amounts of data produced continuously by people, tools, and machines. The challenges associated with the velocity, volume, and variety of big data have led to the development of specialized processing tools and platforms, including:

- **Apache Hadoop**
- **Apache Hive**
- **Apache Spark**

These tools are designed to handle and analyze large datasets efficiently.
